{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEResnet8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucalyptus/BS-Nets-Implementation-Pytorch/blob/master/SEResnet8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6OCqhHxm53M",
        "colab_type": "code",
        "outputId": "9318566b-4abe-410c-bdae-92218a8761ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install spectral\n",
        "!pip3 install keras==2.2.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.17.4)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfHocU4InF6n",
        "colab_type": "code",
        "outputId": "c24827ac-909a-428d-e150-971b1106177b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from keras.layers import Dropout, Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNUo-GmrYQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random \n",
        "#import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Input\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.optimizers import Adam, SGD, Adadelta, RMSprop, Nadam\n",
        "import keras.callbacks as kcallbacks\n",
        "from keras.regularizers import l2\n",
        "import time\n",
        "import collections\n",
        "from sklearn import metrics, preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEDB7COnnLWB",
        "colab_type": "code",
        "outputId": "8232b95a-a238-4855-e631-e2f12702c7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTg1gBApnYB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(name):\n",
        "    data_path = '/content/gdrive/My Drive/HSI/data/'\n",
        "    if name == 'IP':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    elif name == 'KSC':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'KSC.mat'))['KSC']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'KSC_gt.mat'))['KSC_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jTK5lVknd1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GLOBAL VARIABLES\n",
        "dataset = 'IP'\n",
        "test_ratio = 0.7\n",
        "windowSize = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aUueS0ongcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPNszbeGnnz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWXLXtjUnq6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lex5klJMnuE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createImageCubes(X, y, windowSize=15, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAXZ6HZHnxY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X , Y = loadData(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiOD8i_Bnyuz",
        "colab_type": "code",
        "outputId": "73fd6752-dc8f-4948-f423-1330ae209944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "K = 30 if dataset == 'IP' else 15\n",
        "X,pca = applyPCA(X,numComponents=K)\n",
        "\n",
        "X.shape"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145, 145, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4rK5F8LoLPE",
        "colab_type": "code",
        "outputId": "c7c9e185-6f3e-49b8-dbd5-3ca79ebd743b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, Y = createImageCubes(X, Y, windowSize=windowSize)\n",
        "X.shape, Y.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10249, 15, 15, 30), (10249,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwIAVJY3yNeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sz = X.shape[0]//10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuZ2ycEurFKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Y = to_categorical(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfn4Hz5ioNll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape((X.shape[0],windowSize,windowSize,K,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQIbpv2CoQnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, test_X, train_Y, test_Y = splitTrainTestSet(X, Y, test_ratio)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfcURydATbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X.shape\n",
        "#train_X, test_X = X[:160] , X[160:]\n",
        "#train_Y, test_Y = Y[:160] , Y[160:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MugcRnL2q7aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_X = test_X[:sz]\n",
        "test_X = test_X[sz:]\n",
        "val_Y = test_Y[:sz]\n",
        "test_Y = test_Y[sz:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUgh__zLlAYU",
        "colab_type": "code",
        "outputId": "8d0b62bc-1acb-4e83-d1e0-0226b10f1344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3074, 15, 15, 30, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSNCVEq0o06C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KAPPA_RES_SS4 = []\n",
        "OA_RES_SS4 = []\n",
        "AA_RES_SS4 = []\n",
        "TRAINING_TIME_RES_SS4 = []\n",
        "TESTING_TIME_RES_SS4 = []\n",
        "ELEMENT_ACC_RES_SS4 = np.zeros((1, 16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKgAJNHEtB69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm se_resnet8_cbof.py\n",
        "#!rm cbof.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1YcGdejo-b1",
        "colab_type": "code",
        "outputId": "1ac9fc29-4a28-4912-ae92-e637da2b99b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "from google.colab import files\n",
        "Utils = files.upload()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8890b2d9-7ec8-4450-9d8e-f21c571cb2fd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8890b2d9-7ec8-4450-9d8e-f21c571cb2fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-3dfdb59521fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mUtils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read property '_uploadFiles' of undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcsgrLOcpIOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import se_resnet8_cbof\n",
        "import cbof"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEGqqjvGo7dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res4_model_ss():\n",
        "    model_res4  = se_resnet8_cbof.SE_ResNet8((1, windowSize, windowSize, K),16,64)\n",
        "\n",
        "    RMS = RMSprop(lr=0.0003)\n",
        "    # Let's train the model using RMSprop\n",
        "    model_res4.compile(loss='categorical_crossentropy', optimizer=RMS, metrics=['accuracy'])\n",
        "\n",
        "    return model_res4 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcIWdOQptX3",
        "colab_type": "code",
        "outputId": "6ec1d648-f197-4614-e9ce-f789e2196b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "data_path = '/content/gdrive/My Drive/Swalpa/SE_RESNET8/'\n",
        "os.listdir(data_path)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utils3.rar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqSt4FnqaFj",
        "colab_type": "code",
        "outputId": "9d73b42a-410d-4a8a-d794-0669ebd19b20",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "from google.colab import files\n",
        "fl = files.upload()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c0bca78-b36b-43f1-aba6-c8ae0a7e1d86\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6c0bca78-b36b-43f1-aba6-c8ae0a7e1d86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M16p-17_qjwv",
        "colab_type": "code",
        "outputId": "4c5552e6-05fa-4428-cde9-f9e7b0b56347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!unrar e -y utils3.rar"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from utils3.rar\n",
            "\n",
            "Extracting  averageAccuracy.py                                           \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  doPCA.py                                                     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  modelStatsRecord.py                                          \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  New Text Document.txt                                        \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  normalization.py                                             \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  Rawdata_3D_ResNet.py                                         \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  Real3D_conv.py                                               \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  ssrn_SS_IN.py                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  zeroPadding.py                                               \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCplSuzfuC1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zeroPadding\n",
        "import normalization\n",
        "import doPCA\n",
        "import modelStatsRecord\n",
        "import averageAccuracy\n",
        "import ssrn_SS_IN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdTRC500pcsr",
        "colab_type": "code",
        "outputId": "e68d0052-c6eb-4e00-fff9-78de97b08b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index_iter in range(1):\n",
        "    print(\"# %d Iteration\" % (index_iter + 1))\n",
        "\n",
        "    # save the best validated model \n",
        "    \n",
        "    best_weights_RES_path_ss4 = data_path+ 'Model_' + dataset +'/' + str(\n",
        "        index_iter + 1) + '_NEW_KERNEL32_20_B_32_se.hdf5'\n",
        "\n",
        "    \n",
        "\n",
        "    # TRAIN_SIZE = len(train_indices)\n",
        "    # print (TRAIN_SIZE)\n",
        "    #\n",
        "    # TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE - VAL_SIZE\n",
        "    # print (TEST_SIZE)\n",
        "\n",
        "    # print (\"Validation data:\")\n",
        "    # collections.Counter(y_test_raw[-VAL_SIZE:])\n",
        "    # print (\"Testing data:\")\n",
        "    # collections.Counter(y_test_raw[:-VAL_SIZE])\n",
        "\n",
        "    #train_assign = indexToAssignment(train_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
        "    #for i in range(len(train_assign)):\n",
        "    #    train_data[i] = selectNeighboringPatch(padded_data, train_assign[i][0], train_assign[i][1], PATCH_LENGTH)\n",
        "\n",
        "    #test_assign = indexToAssignment(test_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
        "    #for i in range(len(test_assign)):\n",
        "    #    test_data[i] = selectNeighboringPatch(padded_data, test_assign[i][0], test_assign[i][1], PATCH_LENGTH)\n",
        "\n",
        "    #train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], train_X.shape[2], 30)\n",
        "    #test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], test_X.shape[2], 30)\n",
        "    #val_X = val_X.reshape(val_X.shape[0], val_X.shape[1], val_X.shape[2], 30)\n",
        "\n",
        "    #x_val = x_test_all[-VAL_SIZE:]\n",
        "    #y_val = y_test[-VAL_SIZE:]\n",
        "\n",
        "    #x_test = x_test_all[:-VAL_SIZE]\n",
        "   # y_test = y_test[:-VAL_SIZE]\n",
        "\n",
        "    # SS Residual Network 4 with BN\n",
        "    model_res4_SS_BN = res4_model_ss()\n",
        "\n",
        "    earlyStopping6 = kcallbacks.EarlyStopping(monitor='val_loss', patience=200, verbose=1, mode='auto')\n",
        "    saveBestModel6 = kcallbacks.ModelCheckpoint(best_weights_RES_path_ss4, monitor='val_loss', verbose=1,\n",
        "                                                save_best_only=True,\n",
        "                                                mode='auto')\n",
        "\n",
        "    tic6 = time.clock()\n",
        "    print(train_X.shape, test_X.shape)\n",
        "    history_res4_SS_BN = model_res4_SS_BN.fit(\n",
        "        train_X, train_Y,\n",
        "        validation_data=(val_X, val_Y),\n",
        "        batch_size=32,\n",
        "        epochs=200, shuffle=True, callbacks=[earlyStopping6])#,saveBestModel6])\n",
        "    toc6 = time.clock()\n",
        "\n",
        "    tic7 = time.clock()\n",
        "    loss_and_metrics_res4_SS_BN = model_res4_SS_BN.evaluate(\n",
        "        test_X, test_Y,\n",
        "        batch_size=32)\n",
        "    toc7 = time.clock()\n",
        "\n",
        "    print('3D RES_SS4 without BN Training Time: ', toc6 - tic6)\n",
        "    print('3D RES_SS4 without BN Test time:', toc7 - tic7)\n",
        "\n",
        "    print('3D RES_SS4 without BN Test score:', loss_and_metrics_res4_SS_BN[0])\n",
        "    print('3D RES_SS4 without BN Test accuracy:', loss_and_metrics_res4_SS_BN[1])\n",
        "\n",
        "    print(history_res4_SS_BN.history.keys())\n",
        "\n",
        "    pred_test_res4 = model_res4_SS_BN.predict(test_X).argmax(axis=1)\n",
        "    collections.Counter(pred_test_res4)\n",
        "    gt_test = test_Y\n",
        "    overall_acc_res4 = metrics.accuracy_score(pred_test_res4, gt_test.argmax(axis=1))\n",
        "    confusion_matrix_res4 = metrics.confusion_matrix(pred_test_res4, gt_test.argmax(axis=1))\n",
        "    each_acc_res4, average_acc_res4 = averageAccuracy.AA_andEachClassAccuracy(confusion_matrix_res4)\n",
        "    kappa = metrics.cohen_kappa_score(pred_test_res4, gt_test.argmax(axis=1))\n",
        "    KAPPA_RES_SS4.append(kappa)\n",
        "    OA_RES_SS4.append(overall_acc_res4)\n",
        "    AA_RES_SS4.append(average_acc_res4)\n",
        "    TRAINING_TIME_RES_SS4.append(toc6 - tic6)\n",
        "    TESTING_TIME_RES_SS4.append(toc7 - tic7)\n",
        "    ELEMENT_ACC_RES_SS4[index_iter, :] = each_acc_res4\n",
        "\n",
        "    print(\"3D RESNET_SS4 without BN training finished.\")\n",
        "    print(\"# %d Iteration\" % (index_iter + 1))\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 1 Iteration\n",
            "input shape: (None, 15, 15, 12, 64)\n",
            "input shape: (None, 13, 13, 1, 64)\n",
            "(?, 13, 13, 1, 64)\n",
            "(?, 13, 13, 64)\n",
            "(None, 13, 13, 64)\n",
            "call\n",
            "output\n",
            "(None, 13, 13, 64)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 15, 15, 30, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_41 (Conv3D)              (None, 15, 15, 12, 6 512         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 15, 15, 12, 6 256         conv3d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 15, 15, 12, 6 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_42 (Conv3D)              (None, 15, 15, 12, 6 36928       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 15, 15, 12, 6 256         conv3d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 15, 15, 12, 6 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_43 (Conv3D)              (None, 15, 15, 12, 6 36928       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_11 (Global (None, 64)           0           conv3d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 1, 1, 64)     0           global_max_pooling3d_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 1, 1, 4)      256         reshape_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 1, 1, 64)     256         dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, 15, 15, 12, 6 0           conv3d_43[0][0]                  \n",
            "                                                                 dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 15, 15, 12, 6 0           multiply_11[0][0]                \n",
            "                                                                 conv3d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 15, 15, 12, 6 256         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 15, 15, 12, 6 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_44 (Conv3D)              (None, 15, 15, 1, 64 49216       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 15, 15, 1, 64 256         conv3d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 15, 15, 1, 64 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 15, 15, 64, 1 0           activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_45 (Conv3D)              (None, 13, 13, 1, 64 36928       reshape_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 13, 13, 1, 64 256         conv3d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 13, 13, 1, 64 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_48 (Conv3D)              (None, 13, 13, 1, 64 4160        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_12 (Global (None, 64)           0           conv3d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 1, 1, 64)     0           global_max_pooling3d_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_46 (Conv3D)              (None, 13, 13, 1, 64 36928       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 1, 1, 4)      256         reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 13, 13, 1, 64 256         conv3d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 1, 1, 64)     256         dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 13, 13, 1, 64 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_12 (Multiply)          (None, 13, 13, 1, 64 0           conv3d_48[0][0]                  \n",
            "                                                                 dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_47 (Conv3D)              (None, 13, 13, 1, 64 36928       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 13, 13, 1, 64 0           multiply_12[0][0]                \n",
            "                                                                 conv3d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 13, 13, 1, 64 256         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 13, 13, 1, 64 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 13, 13, 1, 64 256         activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 13, 13, 1, 64 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_24 (Reshape)            (None, Dimension(13) 0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bo_f__pooling_6 (BoF_Pooling)   (None, 64)           4160        reshape_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64)           0           bo_f__pooling_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 16)           1040        dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 246,800\n",
            "Trainable params: 245,776\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "(3074, 15, 15, 30, 1) (6151, 15, 15, 30, 1)\n",
            "Train on 3074 samples, validate on 1024 samples\n",
            "Epoch 1/200\n",
            "3074/3074 [==============================] - 8s 3ms/step - loss: 6.5330 - acc: 0.1620 - val_loss: 6.6746 - val_acc: 0.1504\n",
            "Epoch 2/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 4.6289 - acc: 0.2602 - val_loss: 4.7219 - val_acc: 0.2744\n",
            "Epoch 3/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 3.1343 - acc: 0.3920 - val_loss: 2.7805 - val_acc: 0.5156\n",
            "Epoch 4/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 1.9856 - acc: 0.5673 - val_loss: 2.3902 - val_acc: 0.6582\n",
            "Epoch 5/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 1.5390 - acc: 0.6568 - val_loss: 1.4488 - val_acc: 0.8027\n",
            "Epoch 6/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 1.2985 - acc: 0.7056 - val_loss: 0.6546 - val_acc: 0.8994\n",
            "Epoch 7/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.9965 - acc: 0.7684 - val_loss: 0.8496 - val_acc: 0.8750\n",
            "Epoch 8/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.8911 - acc: 0.8045 - val_loss: 0.7320 - val_acc: 0.9102\n",
            "Epoch 9/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.7326 - acc: 0.8370 - val_loss: 0.4274 - val_acc: 0.9551\n",
            "Epoch 10/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.6693 - acc: 0.8656 - val_loss: 0.5814 - val_acc: 0.9219\n",
            "Epoch 11/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.5504 - acc: 0.8858 - val_loss: 0.3912 - val_acc: 0.9590\n",
            "Epoch 12/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.5070 - acc: 0.9018 - val_loss: 0.4445 - val_acc: 0.9482\n",
            "Epoch 13/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.4388 - acc: 0.9206 - val_loss: 0.5381 - val_acc: 0.9277\n",
            "Epoch 14/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.4591 - acc: 0.9236 - val_loss: 0.3717 - val_acc: 0.9688\n",
            "Epoch 15/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.4179 - acc: 0.9281 - val_loss: 0.3419 - val_acc: 0.9727\n",
            "Epoch 16/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.4464 - acc: 0.9288 - val_loss: 0.2734 - val_acc: 0.9551\n",
            "Epoch 17/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.4975 - acc: 0.9148 - val_loss: 0.2906 - val_acc: 0.9463\n",
            "Epoch 18/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.3432 - acc: 0.9395 - val_loss: 0.4310 - val_acc: 0.9170\n",
            "Epoch 19/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.3626 - acc: 0.9340 - val_loss: 0.3193 - val_acc: 0.9551\n",
            "Epoch 20/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.3217 - acc: 0.9424 - val_loss: 0.4906 - val_acc: 0.9062\n",
            "Epoch 21/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.3368 - acc: 0.9437 - val_loss: 0.4556 - val_acc: 0.9443\n",
            "Epoch 22/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2992 - acc: 0.9554 - val_loss: 0.2177 - val_acc: 0.9727\n",
            "Epoch 23/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.3012 - acc: 0.9512 - val_loss: 0.2131 - val_acc: 0.9727\n",
            "Epoch 24/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2567 - acc: 0.9580 - val_loss: 0.1708 - val_acc: 0.9795\n",
            "Epoch 25/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2605 - acc: 0.9551 - val_loss: 0.1685 - val_acc: 0.9824\n",
            "Epoch 26/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2380 - acc: 0.9704 - val_loss: 0.2087 - val_acc: 0.9795\n",
            "Epoch 27/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2386 - acc: 0.9626 - val_loss: 0.2184 - val_acc: 0.9678\n",
            "Epoch 28/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2289 - acc: 0.9655 - val_loss: 0.2520 - val_acc: 0.9678\n",
            "Epoch 29/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2112 - acc: 0.9704 - val_loss: 0.1860 - val_acc: 0.9834\n",
            "Epoch 30/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2345 - acc: 0.9681 - val_loss: 0.2133 - val_acc: 0.9805\n",
            "Epoch 31/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2201 - acc: 0.9678 - val_loss: 0.1647 - val_acc: 0.9854\n",
            "Epoch 32/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2227 - acc: 0.9642 - val_loss: 0.1859 - val_acc: 0.9775\n",
            "Epoch 33/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1808 - acc: 0.9795 - val_loss: 0.2593 - val_acc: 0.9668\n",
            "Epoch 34/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2132 - acc: 0.9688 - val_loss: 0.1748 - val_acc: 0.9795\n",
            "Epoch 35/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1845 - acc: 0.9766 - val_loss: 0.1484 - val_acc: 0.9863\n",
            "Epoch 36/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2098 - acc: 0.9736 - val_loss: 0.3102 - val_acc: 0.9600\n",
            "Epoch 37/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.2079 - acc: 0.9723 - val_loss: 0.1402 - val_acc: 0.9893\n",
            "Epoch 38/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1928 - acc: 0.9743 - val_loss: 0.1652 - val_acc: 0.9854\n",
            "Epoch 39/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1815 - acc: 0.9795 - val_loss: 0.1563 - val_acc: 0.9883\n",
            "Epoch 40/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1721 - acc: 0.9785 - val_loss: 0.2520 - val_acc: 0.9746\n",
            "Epoch 41/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1776 - acc: 0.9785 - val_loss: 0.2638 - val_acc: 0.9609\n",
            "Epoch 42/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1781 - acc: 0.9811 - val_loss: 0.1796 - val_acc: 0.9844\n",
            "Epoch 43/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1644 - acc: 0.9847 - val_loss: 0.1648 - val_acc: 0.9834\n",
            "Epoch 44/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1694 - acc: 0.9844 - val_loss: 0.1599 - val_acc: 0.9893\n",
            "Epoch 45/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1657 - acc: 0.9841 - val_loss: 0.1658 - val_acc: 0.9814\n",
            "Epoch 46/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1836 - acc: 0.9795 - val_loss: 0.1533 - val_acc: 0.9775\n",
            "Epoch 47/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1722 - acc: 0.9789 - val_loss: 0.1400 - val_acc: 0.9912\n",
            "Epoch 48/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1612 - acc: 0.9837 - val_loss: 0.1435 - val_acc: 0.9893\n",
            "Epoch 49/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1526 - acc: 0.9870 - val_loss: 0.1744 - val_acc: 0.9883\n",
            "Epoch 50/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1564 - acc: 0.9876 - val_loss: 0.1377 - val_acc: 0.9932\n",
            "Epoch 51/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1446 - acc: 0.9893 - val_loss: 0.2148 - val_acc: 0.9727\n",
            "Epoch 52/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1582 - acc: 0.9824 - val_loss: 0.1881 - val_acc: 0.9883\n",
            "Epoch 53/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1588 - acc: 0.9847 - val_loss: 0.1883 - val_acc: 0.9873\n",
            "Epoch 54/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1659 - acc: 0.9834 - val_loss: 0.2270 - val_acc: 0.9805\n",
            "Epoch 55/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1416 - acc: 0.9899 - val_loss: 0.1694 - val_acc: 0.9873\n",
            "Epoch 56/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1462 - acc: 0.9854 - val_loss: 0.1997 - val_acc: 0.9814\n",
            "Epoch 57/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1611 - acc: 0.9844 - val_loss: 0.1460 - val_acc: 0.9873\n",
            "Epoch 58/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1433 - acc: 0.9896 - val_loss: 0.2606 - val_acc: 0.9688\n",
            "Epoch 59/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1424 - acc: 0.9876 - val_loss: 0.1713 - val_acc: 0.9912\n",
            "Epoch 60/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1438 - acc: 0.9876 - val_loss: 0.1557 - val_acc: 0.9863\n",
            "Epoch 61/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1393 - acc: 0.9870 - val_loss: 0.1519 - val_acc: 0.9893\n",
            "Epoch 62/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1373 - acc: 0.9912 - val_loss: 0.1765 - val_acc: 0.9883\n",
            "Epoch 63/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1367 - acc: 0.9896 - val_loss: 0.1840 - val_acc: 0.9834\n",
            "Epoch 64/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1400 - acc: 0.9886 - val_loss: 0.1681 - val_acc: 0.9824\n",
            "Epoch 65/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1406 - acc: 0.9880 - val_loss: 0.2332 - val_acc: 0.9736\n",
            "Epoch 66/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1416 - acc: 0.9854 - val_loss: 0.1584 - val_acc: 0.9893\n",
            "Epoch 67/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1394 - acc: 0.9893 - val_loss: 0.1598 - val_acc: 0.9912\n",
            "Epoch 68/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1329 - acc: 0.9896 - val_loss: 0.1682 - val_acc: 0.9902\n",
            "Epoch 69/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1255 - acc: 0.9919 - val_loss: 0.1639 - val_acc: 0.9873\n",
            "Epoch 70/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1337 - acc: 0.9922 - val_loss: 0.1640 - val_acc: 0.9863\n",
            "Epoch 71/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1237 - acc: 0.9922 - val_loss: 0.3624 - val_acc: 0.9395\n",
            "Epoch 72/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1588 - acc: 0.9841 - val_loss: 0.1613 - val_acc: 0.9902\n",
            "Epoch 73/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1326 - acc: 0.9899 - val_loss: 0.3928 - val_acc: 0.9404\n",
            "Epoch 74/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1329 - acc: 0.9935 - val_loss: 0.1618 - val_acc: 0.9883\n",
            "Epoch 75/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1286 - acc: 0.9902 - val_loss: 0.1602 - val_acc: 0.9912\n",
            "Epoch 76/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1207 - acc: 0.9928 - val_loss: 0.1888 - val_acc: 0.9863\n",
            "Epoch 77/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1361 - acc: 0.9893 - val_loss: 0.1986 - val_acc: 0.9873\n",
            "Epoch 78/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1336 - acc: 0.9909 - val_loss: 0.1505 - val_acc: 0.9902\n",
            "Epoch 79/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1291 - acc: 0.9922 - val_loss: 0.1481 - val_acc: 0.9922\n",
            "Epoch 80/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1285 - acc: 0.9889 - val_loss: 0.1695 - val_acc: 0.9893\n",
            "Epoch 81/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1230 - acc: 0.9909 - val_loss: 0.2252 - val_acc: 0.9854\n",
            "Epoch 82/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1259 - acc: 0.9912 - val_loss: 0.1382 - val_acc: 0.9902\n",
            "Epoch 83/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1270 - acc: 0.9899 - val_loss: 0.2025 - val_acc: 0.9854\n",
            "Epoch 84/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1247 - acc: 0.9915 - val_loss: 0.1447 - val_acc: 0.9912\n",
            "Epoch 85/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1219 - acc: 0.9938 - val_loss: 0.2275 - val_acc: 0.9785\n",
            "Epoch 86/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1300 - acc: 0.9906 - val_loss: 0.1734 - val_acc: 0.9922\n",
            "Epoch 87/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1175 - acc: 0.9919 - val_loss: 0.1674 - val_acc: 0.9883\n",
            "Epoch 88/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1171 - acc: 0.9928 - val_loss: 0.2050 - val_acc: 0.9834\n",
            "Epoch 89/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1185 - acc: 0.9954 - val_loss: 0.1472 - val_acc: 0.9951\n",
            "Epoch 90/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1129 - acc: 0.9945 - val_loss: 0.1607 - val_acc: 0.9893\n",
            "Epoch 91/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1214 - acc: 0.9925 - val_loss: 0.1638 - val_acc: 0.9883\n",
            "Epoch 92/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1235 - acc: 0.9935 - val_loss: 0.1594 - val_acc: 0.9912\n",
            "Epoch 93/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1174 - acc: 0.9928 - val_loss: 0.1487 - val_acc: 0.9951\n",
            "Epoch 94/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1251 - acc: 0.9919 - val_loss: 0.3263 - val_acc: 0.9717\n",
            "Epoch 95/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1272 - acc: 0.9899 - val_loss: 0.2452 - val_acc: 0.9775\n",
            "Epoch 96/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1253 - acc: 0.9919 - val_loss: 0.1632 - val_acc: 0.9912\n",
            "Epoch 97/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1150 - acc: 0.9922 - val_loss: 0.1617 - val_acc: 0.9912\n",
            "Epoch 98/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1085 - acc: 0.9961 - val_loss: 0.1516 - val_acc: 0.9922\n",
            "Epoch 99/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1208 - acc: 0.9909 - val_loss: 0.1749 - val_acc: 0.9873\n",
            "Epoch 100/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1177 - acc: 0.9928 - val_loss: 0.1611 - val_acc: 0.9922\n",
            "Epoch 101/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1174 - acc: 0.9928 - val_loss: 0.1482 - val_acc: 0.9922\n",
            "Epoch 102/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1241 - acc: 0.9919 - val_loss: 0.1679 - val_acc: 0.9863\n",
            "Epoch 103/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1170 - acc: 0.9932 - val_loss: 0.2583 - val_acc: 0.9805\n",
            "Epoch 104/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1097 - acc: 0.9941 - val_loss: 0.2031 - val_acc: 0.9854\n",
            "Epoch 105/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1178 - acc: 0.9925 - val_loss: 0.1540 - val_acc: 0.9932\n",
            "Epoch 106/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1193 - acc: 0.9906 - val_loss: 0.1597 - val_acc: 0.9873\n",
            "Epoch 107/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1165 - acc: 0.9935 - val_loss: 0.1525 - val_acc: 0.9912\n",
            "Epoch 108/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1052 - acc: 0.9967 - val_loss: 0.1509 - val_acc: 0.9883\n",
            "Epoch 109/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1208 - acc: 0.9909 - val_loss: 0.1349 - val_acc: 0.9922\n",
            "Epoch 110/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1193 - acc: 0.9902 - val_loss: 0.1788 - val_acc: 0.9912\n",
            "Epoch 111/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1070 - acc: 0.9925 - val_loss: 0.2141 - val_acc: 0.9766\n",
            "Epoch 112/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1076 - acc: 0.9948 - val_loss: 0.1648 - val_acc: 0.9932\n",
            "Epoch 113/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1117 - acc: 0.9948 - val_loss: 0.3202 - val_acc: 0.9717\n",
            "Epoch 114/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1063 - acc: 0.9938 - val_loss: 0.1543 - val_acc: 0.9932\n",
            "Epoch 115/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1110 - acc: 0.9945 - val_loss: 0.2025 - val_acc: 0.9834\n",
            "Epoch 116/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1105 - acc: 0.9922 - val_loss: 0.1850 - val_acc: 0.9883\n",
            "Epoch 117/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1085 - acc: 0.9941 - val_loss: 0.1991 - val_acc: 0.9727\n",
            "Epoch 118/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1037 - acc: 0.9941 - val_loss: 0.2300 - val_acc: 0.9854\n",
            "Epoch 119/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1018 - acc: 0.9964 - val_loss: 0.1644 - val_acc: 0.9883\n",
            "Epoch 120/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1112 - acc: 0.9938 - val_loss: 0.1253 - val_acc: 0.9951\n",
            "Epoch 121/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1066 - acc: 0.9951 - val_loss: 0.5742 - val_acc: 0.9385\n",
            "Epoch 122/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1062 - acc: 0.9935 - val_loss: 0.1846 - val_acc: 0.9873\n",
            "Epoch 123/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1162 - acc: 0.9928 - val_loss: 0.1905 - val_acc: 0.9775\n",
            "Epoch 124/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1076 - acc: 0.9922 - val_loss: 0.1564 - val_acc: 0.9834\n",
            "Epoch 125/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1109 - acc: 0.9922 - val_loss: 0.1387 - val_acc: 0.9912\n",
            "Epoch 126/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1098 - acc: 0.9932 - val_loss: 0.1571 - val_acc: 0.9902\n",
            "Epoch 127/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1136 - acc: 0.9938 - val_loss: 0.4186 - val_acc: 0.9658\n",
            "Epoch 128/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1103 - acc: 0.9954 - val_loss: 0.1961 - val_acc: 0.9863\n",
            "Epoch 129/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1196 - acc: 0.9915 - val_loss: 0.1865 - val_acc: 0.9873\n",
            "Epoch 130/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1131 - acc: 0.9925 - val_loss: 0.1319 - val_acc: 0.9912\n",
            "Epoch 131/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1152 - acc: 0.9919 - val_loss: 0.1988 - val_acc: 0.9854\n",
            "Epoch 132/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1132 - acc: 0.9912 - val_loss: 0.1560 - val_acc: 0.9902\n",
            "Epoch 133/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1126 - acc: 0.9945 - val_loss: 0.1260 - val_acc: 0.9951\n",
            "Epoch 134/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1060 - acc: 0.9948 - val_loss: 0.1543 - val_acc: 0.9902\n",
            "Epoch 135/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1108 - acc: 0.9932 - val_loss: 0.2046 - val_acc: 0.9756\n",
            "Epoch 136/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1071 - acc: 0.9964 - val_loss: 0.1620 - val_acc: 0.9922\n",
            "Epoch 137/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1086 - acc: 0.9948 - val_loss: 0.1560 - val_acc: 0.9922\n",
            "Epoch 138/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1041 - acc: 0.9941 - val_loss: 0.1815 - val_acc: 0.9814\n",
            "Epoch 139/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1066 - acc: 0.9935 - val_loss: 0.1535 - val_acc: 0.9922\n",
            "Epoch 140/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1092 - acc: 0.9922 - val_loss: 0.1538 - val_acc: 0.9932\n",
            "Epoch 141/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1008 - acc: 0.9945 - val_loss: 0.1618 - val_acc: 0.9941\n",
            "Epoch 142/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1061 - acc: 0.9928 - val_loss: 0.2018 - val_acc: 0.9883\n",
            "Epoch 143/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1115 - acc: 0.9915 - val_loss: 0.2022 - val_acc: 0.9873\n",
            "Epoch 144/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1037 - acc: 0.9935 - val_loss: 0.1635 - val_acc: 0.9883\n",
            "Epoch 145/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1102 - acc: 0.9951 - val_loss: 0.1844 - val_acc: 0.9873\n",
            "Epoch 146/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1000 - acc: 0.9958 - val_loss: 0.1493 - val_acc: 0.9932\n",
            "Epoch 147/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1027 - acc: 0.9938 - val_loss: 0.2113 - val_acc: 0.9814\n",
            "Epoch 148/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1202 - acc: 0.9928 - val_loss: 0.1657 - val_acc: 0.9844\n",
            "Epoch 149/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1079 - acc: 0.9935 - val_loss: 0.1535 - val_acc: 0.9912\n",
            "Epoch 150/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1100 - acc: 0.9935 - val_loss: 0.1565 - val_acc: 0.9941\n",
            "Epoch 151/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0989 - acc: 0.9938 - val_loss: 0.1597 - val_acc: 0.9922\n",
            "Epoch 152/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1061 - acc: 0.9935 - val_loss: 0.2924 - val_acc: 0.9756\n",
            "Epoch 153/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1028 - acc: 0.9938 - val_loss: 0.1764 - val_acc: 0.9902\n",
            "Epoch 154/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1011 - acc: 0.9958 - val_loss: 0.1425 - val_acc: 0.9932\n",
            "Epoch 155/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0991 - acc: 0.9954 - val_loss: 0.1554 - val_acc: 0.9912\n",
            "Epoch 156/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1059 - acc: 0.9945 - val_loss: 0.1320 - val_acc: 0.9902\n",
            "Epoch 157/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0997 - acc: 0.9964 - val_loss: 0.1304 - val_acc: 0.9932\n",
            "Epoch 158/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1017 - acc: 0.9958 - val_loss: 0.2042 - val_acc: 0.9863\n",
            "Epoch 159/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1093 - acc: 0.9928 - val_loss: 0.1099 - val_acc: 0.9961\n",
            "Epoch 160/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0984 - acc: 0.9954 - val_loss: 0.1527 - val_acc: 0.9902\n",
            "Epoch 161/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1006 - acc: 0.9948 - val_loss: 0.1239 - val_acc: 0.9912\n",
            "Epoch 162/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1085 - acc: 0.9941 - val_loss: 0.1780 - val_acc: 0.9873\n",
            "Epoch 163/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1005 - acc: 0.9961 - val_loss: 0.1991 - val_acc: 0.9854\n",
            "Epoch 164/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1061 - acc: 0.9912 - val_loss: 0.1992 - val_acc: 0.9824\n",
            "Epoch 165/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1008 - acc: 0.9954 - val_loss: 0.2582 - val_acc: 0.9775\n",
            "Epoch 166/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1007 - acc: 0.9935 - val_loss: 0.1386 - val_acc: 0.9902\n",
            "Epoch 167/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1084 - acc: 0.9880 - val_loss: 0.1953 - val_acc: 0.9873\n",
            "Epoch 168/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1026 - acc: 0.9954 - val_loss: 0.1790 - val_acc: 0.9912\n",
            "Epoch 169/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1075 - acc: 0.9922 - val_loss: 0.1179 - val_acc: 0.9961\n",
            "Epoch 170/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1064 - acc: 0.9948 - val_loss: 0.1337 - val_acc: 0.9932\n",
            "Epoch 171/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1149 - acc: 0.9909 - val_loss: 0.1615 - val_acc: 0.9893\n",
            "Epoch 172/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1054 - acc: 0.9945 - val_loss: 0.1579 - val_acc: 0.9902\n",
            "Epoch 173/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0920 - acc: 0.9964 - val_loss: 0.1336 - val_acc: 0.9941\n",
            "Epoch 174/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0897 - acc: 0.9974 - val_loss: 0.1499 - val_acc: 0.9902\n",
            "Epoch 175/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0977 - acc: 0.9948 - val_loss: 0.1618 - val_acc: 0.9932\n",
            "Epoch 176/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1023 - acc: 0.9935 - val_loss: 0.1585 - val_acc: 0.9941\n",
            "Epoch 177/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1015 - acc: 0.9945 - val_loss: 0.1264 - val_acc: 0.9961\n",
            "Epoch 178/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0984 - acc: 0.9928 - val_loss: 0.1140 - val_acc: 0.9961\n",
            "Epoch 179/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0867 - acc: 0.9984 - val_loss: 0.1416 - val_acc: 0.9922\n",
            "Epoch 180/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0966 - acc: 0.9941 - val_loss: 0.1244 - val_acc: 0.9932\n",
            "Epoch 181/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1008 - acc: 0.9945 - val_loss: 0.1750 - val_acc: 0.9883\n",
            "Epoch 182/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0960 - acc: 0.9935 - val_loss: 0.1426 - val_acc: 0.9922\n",
            "Epoch 183/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0869 - acc: 0.9977 - val_loss: 0.1916 - val_acc: 0.9883\n",
            "Epoch 184/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0918 - acc: 0.9945 - val_loss: 0.1616 - val_acc: 0.9873\n",
            "Epoch 185/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0958 - acc: 0.9938 - val_loss: 0.1877 - val_acc: 0.9824\n",
            "Epoch 186/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0947 - acc: 0.9948 - val_loss: 0.1513 - val_acc: 0.9922\n",
            "Epoch 187/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0995 - acc: 0.9935 - val_loss: 0.1976 - val_acc: 0.9883\n",
            "Epoch 188/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1034 - acc: 0.9928 - val_loss: 0.1532 - val_acc: 0.9912\n",
            "Epoch 189/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0909 - acc: 0.9964 - val_loss: 0.1213 - val_acc: 0.9902\n",
            "Epoch 190/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1039 - acc: 0.9932 - val_loss: 0.1583 - val_acc: 0.9922\n",
            "Epoch 191/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0912 - acc: 0.9951 - val_loss: 0.1402 - val_acc: 0.9932\n",
            "Epoch 192/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1052 - acc: 0.9941 - val_loss: 0.1594 - val_acc: 0.9893\n",
            "Epoch 193/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0961 - acc: 0.9948 - val_loss: 0.1507 - val_acc: 0.9893\n",
            "Epoch 194/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.1006 - acc: 0.9932 - val_loss: 0.1727 - val_acc: 0.9922\n",
            "Epoch 195/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0911 - acc: 0.9941 - val_loss: 0.1692 - val_acc: 0.9912\n",
            "Epoch 196/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0945 - acc: 0.9945 - val_loss: 0.1178 - val_acc: 0.9951\n",
            "Epoch 197/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0943 - acc: 0.9945 - val_loss: 0.2102 - val_acc: 0.9814\n",
            "Epoch 198/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0932 - acc: 0.9961 - val_loss: 0.2908 - val_acc: 0.9795\n",
            "Epoch 199/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0881 - acc: 0.9967 - val_loss: 0.1528 - val_acc: 0.9912\n",
            "Epoch 200/200\n",
            "3074/3074 [==============================] - 4s 1ms/step - loss: 0.0894 - acc: 0.9961 - val_loss: 0.1618 - val_acc: 0.9902\n",
            "6151/6151 [==============================] - 3s 420us/step\n",
            "3D RES_SS4 without BN Training Time:  923.023263\n",
            "3D RES_SS4 without BN Test time: 2.905518999999913\n",
            "3D RES_SS4 without BN Test score: 0.140724551529201\n",
            "3D RES_SS4 without BN Test accuracy: 0.9925215412128109\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
            "3D RESNET_SS4 without BN training finished.\n",
            "# 1 Iteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlTFH_gb7TNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!touch /content/1.txt\n",
        "!touch /content/2.txt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOraOszd59pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "364d88c5-d5ea-460f-8584-71365643e0c3"
      },
      "source": [
        "modelStatsRecord.outputStats(KAPPA_RES_SS4, OA_RES_SS4, AA_RES_SS4, ELEMENT_ACC_RES_SS4,\n",
        "                             TRAINING_TIME_RES_SS4, TESTING_TIME_RES_SS4,\n",
        "                             history_res4_SS_BN, loss_and_metrics_res4_SS_BN, 16,\n",
        "                             #data_path\n",
        "                             '/content/' +'1.txt',\n",
        "                             #'/IN_train_RESNET8_KERNEL32_20_B_64_bcof_64_nooverlapping_7.txt',\n",
        "                             #data_path\n",
        "                             '/content/'+ '2.txt')\n",
        "                              #+'Model_' + dataset +\n",
        "                             #'/IN_train_RESNET8_KERNEL32_20_B_32_IP_element_10_bcof_64_nooverlapping_7.txt')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.140724551529201\n",
            "Test accuracy: 0.9925215412128109\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs27DnwmMxlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist1_val_acc = history_res4_SS_BN.history['val_acc']\n",
        "hist1_val_loss = history_res4_SS_BN.history['val_loss']\n",
        "hist1_acc = history_res4_SS_BN.history['acc']\n",
        "hist1_loss = history_res4_SS_BN.history['loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kXrQzebMrO3",
        "colab_type": "code",
        "outputId": "31454666-5895-404d-bfd9-e91f0b933fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "% matplotlib inline\n",
        "matplotlib.rcParams.update({'font.size': 16})\n",
        "\n",
        "# summarize history for accuracy\n",
        "f = plt.figure()\n",
        "\n",
        "plt.plot(hist1_acc , color='red',linestyle='solid', label = 'Training')\n",
        "plt.plot(hist1_val_acc , color='red',linestyle='dashed', label = 'Validation')\n",
        "\n",
        "#plt.ylim(0, 3)   \n",
        "#plt.xlim(0,50)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.legend(prop={'size': 12})\n",
        "\n",
        "\n",
        "#plt.legend(['train', 'val'], loc='lower left')\n",
        "plt.show()\n",
        "#f.savefig(\"/content/gdrive/My Drive/Fuseacc.pdf\")\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEQCAYAAACa+vIpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niXPOubj8f8fKn8c7T49sAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI6xF3pDNMBY",
        "colab_type": "code",
        "outputId": "f93e3e7b-c496-4659-abc9-45b5bffb9838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# summarize history for loss\n",
        "# summarize history for accuracy\n",
        "f = plt.figure()\n",
        "\n",
        "\n",
        "plt.plot(hist1_loss , color='green',linestyle='solid', label = 'Training')\n",
        "plt.plot(hist1_val_loss , color='green',linestyle='dashed', label = 'Validation')\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "#plt.xlim(0,26)\n",
        "#plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#f.savefig(\"/content/gdrive/My Drive/loss_new_UP_green.pdf\")\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEQCAYAAAC9VHPBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk5NEIIQQJvf/OSQgk/JfYOIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}