{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSI-SE-Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucalyptus/BS-Nets-Implementation-Pytorch/blob/master/HSI_SE_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS66_B24E9bG",
        "colab_type": "code",
        "outputId": "3dcb163d-cc2b-4a28-e292-b64e162f4def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ5Db4oyE_hM",
        "colab_type": "code",
        "outputId": "b79753e1-d838-41dc-c707-42aeea49099d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "!pip install spectral\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spectral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/8e/db1d750fb0153027e4e945f91f04b72a3b8b9a0cfdc2c8a33bedcb27740d/spectral-0.20.tar.gz (143kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 28.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.17.3)\n",
            "Building wheels for collected packages: spectral\n",
            "  Building wheel for spectral (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectral: filename=spectral-0.20-cp36-none-any.whl size=183918 sha256=1f82b4248a58d9fdf276ddd32041adda342035dc87d086f2c81bb146d04d9804\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/cf/f3/3cab28f6aed46f15c8db09c6ad678483610426261025e61ff8\n",
            "Successfully built spectral\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.20\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSVPTB-YlsiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.getcwd()+'/drive/My Drive/HSI/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rCOGapkEuEy",
        "colab_type": "code",
        "outputId": "0f3c7d1b-b871-461b-d7c0-ff2541927636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import scipy\n",
        "\n",
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, BatchNormalization, Activation \n",
        "from keras.layers import Add, Permute, Multiply, Dropout, Input, Concatenate, Reshape\n",
        "from keras.layers import GlobalMaxPooling3D, GlobalAveragePooling3D, MaxPooling2D \n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import spectral\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i122IZ7iEuE8",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqUpb5agEuE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GLOBAL VARIABLES\n",
        "dataset = 'IP'\n",
        "test_ratio = 0.85\n",
        "windowSize = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E24L5BNbEuFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(name):\n",
        "    data_path = os.path.join(os.getcwd()+'/drive/My Drive/HSI/','data')\n",
        "    if name == 'IP':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN-2flqsEuFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpebiO1BEuFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47l9ig_JEuFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V8IiC60EuFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5rZDWwWEuFk",
        "colab_type": "code",
        "outputId": "f870f309-14dd-4baf-bf96-c71319e5f86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = loadData(dataset)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((145, 145, 200), (145, 145))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxrExuUEuFw",
        "colab_type": "code",
        "outputId": "e1a69170-cecb-4ca2-95a9-c69b9ca918fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "L = 30 if dataset == 'IP' else 15\n",
        "X,pca = applyPCA(X,numComponents=L)\n",
        "\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145, 145, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAVUs31yEuF1",
        "colab_type": "code",
        "outputId": "413c5a9b-ddc8-41e6-df7c-83edcfca03c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10249, 15, 15, 30), (10249,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYqeWiwNEuF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2RdCPRrTgAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, L, 1)\n",
        "ytrain = np_utils.to_categorical(ytrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpxWf5tgTf0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest = Xtest.reshape(-1, windowSize, windowSize, L, 1)\n",
        "ytest = np_utils.to_categorical(ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBf755Q0T5Tl",
        "colab_type": "code",
        "outputId": "1c602d13-4d53-4a5e-a877-d81c6f22aa53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1537, 15, 15, 30, 1), (8712, 15, 15, 30, 1), (1537, 16), (8712, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r3puatRAkYD",
        "colab_type": "text"
      },
      "source": [
        "# CBOF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUFSZp8TAjt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.topology import Layer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dtTSaCAq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bof = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl6EmhPaAs2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoF_Pooling(Layer):\n",
        "    def __init__(self, n_codewords, spatial_level=0, **kwargs):\n",
        "        self.N_k = n_codewords\n",
        "        self.spatial_level = spatial_level\n",
        "        self.V, self.sigmas = None, None\n",
        "\n",
        "        super(BoF_Pooling, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.V = self.add_weight(name='codebook', shape=(1, 1, input_shape[3], self.N_k), initializer='uniform',\n",
        "                                 trainable=True)\n",
        "        self.sigmas = self.add_weight(name='sigmas', shape=(1, 1, 1, self.N_k), initializer=Constant(0.1),\n",
        "                                      trainable=True)\n",
        "        super(BoF_Pooling, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Calculate the pairwise distances between the codewords and the feature vectors\n",
        "        x_square = K.sum(x ** 2, axis=3, keepdims=True)\n",
        "        y_square = K.sum(self.V ** 2, axis=2, keepdims=True)\n",
        "        dists = x_square + y_square - 2 * K.conv2d(x, self.V, strides=(1, 1), padding='valid')\n",
        "        dists = K.maximum(dists, 0)\n",
        "\n",
        "        # Quantize the feature vectors\n",
        "        quantized_features = K.softmax(- dists / (self.sigmas ** 2))\n",
        "\n",
        "        # Compile the histogram\n",
        "        if self.spatial_level == 0:\n",
        "            histogram = K.mean(quantized_features, [1, 2])\n",
        "        elif self.spatial_level == 1:\n",
        "            shape = K.shape(quantized_features)\n",
        "            mid_1 = K.cast(shape[1] / 2, 'int32')\n",
        "            mid_2 = K.cast(shape[2] / 2, 'int32')\n",
        "            histogram1 = K.mean(quantized_features[:, :mid_1, :mid_2, :], [1, 2])\n",
        "            histogram2 = K.mean(quantized_features[:, mid_1:, :mid_2, :], [1, 2])\n",
        "            histogram3 = K.mean(quantized_features[:, :mid_1, mid_2:, :], [1, 2])\n",
        "            histogram4 = K.mean(quantized_features[:, mid_1:, mid_2:, :], [1, 2])\n",
        "            histogram = K.stack([histogram1, histogram2, histogram3, histogram4], 1)\n",
        "            histogram = K.reshape(histogram, (-1, 4 * self.N_k))\n",
        "        else:\n",
        "            # No other spatial level is currently supported (it is trivial to extend the code)\n",
        "            assert False\n",
        "\n",
        "        # Simple trick to avoid rescaling issues\n",
        "        return histogram * self.N_k\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.spatial_level == 0:\n",
        "            return (input_shape[0], self.N_k)\n",
        "        elif self.spatial_level == 1:\n",
        "            return (input_shape[0], 4 * self.N_k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaxQwVWVYksX",
        "colab_type": "text"
      },
      "source": [
        "# Model Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scD6zx4oYdqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    merge,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Dropout\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Convolution3D,\n",
        "    MaxPooling3D,\n",
        "    AveragePooling3D,\n",
        "    Conv3D\n",
        ")\n",
        "#import cbof\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling3D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling3D\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import add\n",
        "\n",
        "from keras.layers import maximum\n",
        "from keras.layers import multiply\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import conv_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras_applications.resnet50 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "from keras.regularizers import l2\n",
        "from keras import regularizers\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMaRII15Y7cX",
        "colab_type": "text"
      },
      "source": [
        "# SE-Resnet8 subfunctions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhiYfywVYpk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _handle_dim_ordering():\n",
        "    global CONV_DIM1\n",
        "    global CONV_DIM2\n",
        "    global CONV_DIM3\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        CONV_DIM1 = 1\n",
        "        CONV_DIM2 = 2\n",
        "        CONV_DIM3 = 3\n",
        "        CHANNEL_AXIS = 4\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        CONV_DIM1 = 2\n",
        "        CONV_DIM2 = 3\n",
        "        CONV_DIM3 = 4\n",
        "\n",
        "def _bn_relu(input):\n",
        "\tnorm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "\treturn Activation(\"relu\")(norm)\n",
        "\n",
        "def _conv_bn_relu(**params):\n",
        "    nb_filter = params[\"nb_filter\"]\n",
        "    kernel_dim1 = params[\"kernel_dim1\"]\n",
        "    kernel_dim2 = params[\"kernel_dim2\"]\n",
        "    kernel_dim3 = params[\"kernel_dim3\"]\n",
        "    subsample = params.setdefault(\"subsample\", (1, 1, 1))\n",
        "    init = params.setdefault(\"init\", \"he_normal\")\n",
        "    border_mode = params.setdefault(\"border_mode\", \"same\")\n",
        "    W_regularizer = params.setdefault(\"W_regularizer\", regularizers.l2(1.e-4))\n",
        "    def f(input):\n",
        "        conv = Conv3D(kernel_initializer=init,strides=subsample,kernel_regularizer= W_regularizer, filters=nb_filter, kernel_size=(kernel_dim1,kernel_dim2,kernel_dim3))(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _bn_relu_conv(**params):\n",
        "    nb_filter = params[\"nb_filter\"]\n",
        "    kernel_dim1 = params[\"kernel_dim1\"]\n",
        "    kernel_dim2 = params[\"kernel_dim2\"]\n",
        "    kernel_dim3 = params[\"kernel_dim3\"]\n",
        "    subsample = params.setdefault(\"subsample\", (1,1,1))\n",
        "    init = params.setdefault(\"init\", \"he_normal\")\n",
        "    border_mode = params.setdefault(\"border_mode\", \"same\")\n",
        "    W_regularizer = params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv3D(kernel_initializer=init, strides=subsample, kernel_regularizer=W_regularizer,\n",
        "                          filters=nb_filter, kernel_size=(kernel_dim1, kernel_dim2, kernel_dim3), padding=border_mode)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    stride_dim1 = (input._keras_shape[CONV_DIM1]+1) // residual._keras_shape[CONV_DIM1]\n",
        "    stride_dim2 = (input._keras_shape[CONV_DIM2]+1) // residual._keras_shape[CONV_DIM2]\n",
        "    stride_dim3 = (input._keras_shape[CONV_DIM3]+1) // residual._keras_shape[CONV_DIM3]\n",
        "    equal_channels = residual._keras_shape[CHANNEL_AXIS] == input._keras_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    print(\"input shape:\", input._keras_shape)\n",
        "\n",
        "    shortcut = Conv3D(kernel_initializer=\"he_normal\", strides=(stride_dim1, stride_dim2, stride_dim3), kernel_regularizer=regularizers.l2(0.0001),filters=residual._keras_shape[CHANNEL_AXIS], kernel_size=(1, 1, 1), padding='valid')(input)\n",
        "    #shortcut = channel_spatial_squeeze_excite(shortcut)\n",
        "    shortcut = squeeze_excite_gap_block(shortcut)\n",
        "    \n",
        "    return add([shortcut, residual])\n",
        "\t\n",
        "def _shortcut_spc(input, residual):\n",
        "    stride_dim1 = (input._keras_shape[CONV_DIM1]+1) // residual._keras_shape[CONV_DIM1]\n",
        "    stride_dim2 = (input._keras_shape[CONV_DIM2]+1) // residual._keras_shape[CONV_DIM2]\n",
        "    stride_dim3 = (input._keras_shape[CONV_DIM3]+1) // residual._keras_shape[CONV_DIM3]\n",
        "    equal_channels = residual._keras_shape[CHANNEL_AXIS] == input._keras_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    print(\"input shape:\", input._keras_shape)\n",
        "    #shortcut = channel_spatial_squeeze_excite(residual)\n",
        "    shortcut = squeeze_excite_gap_block(shortcut)\n",
        "    return add([shortcut, residual])\n",
        "\t\n",
        "\t\n",
        "def basic_block(nb_filter, init_subsample=(1, 1, 1), is_first_block_of_first_layer=False):\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            conv1 = Conv3D(kernel_initializer=\"he_normal\", strides=init_subsample, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                          filters=nb_filter, kernel_size=(3, 3, 1), padding='same')(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(nb_filter=nb_filter, kernel_dim1=3, kernel_dim2=3, kernel_dim3=1, subsample=init_subsample)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(nb_filter=nb_filter, kernel_dim1=3, kernel_dim2=3, kernel_dim3=1)(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "def basic_block_spc(nb_filter, init_subsample=(1, 1, 1), is_first_block_of_first_layer=False):\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            conv1 = Conv3D(kernel_initializer=\"he_normal\", strides=init_subsample, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                          filters=nb_filter, kernel_size=(3, 3, 1), padding='same')(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(nb_filter=nb_filter, kernel_dim1=3, kernel_dim2=3, kernel_dim3=1, subsample=init_subsample)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(nb_filter=nb_filter, kernel_dim1=3, kernel_dim2=3, kernel_dim3=1)(conv1)\n",
        "        return _shortcut_spc(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMLlE-1uZW3t",
        "colab_type": "text"
      },
      "source": [
        "# Squeeze Excitation Combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbikLT5FZbHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squeeze_excite_gap_block(input, ratio=16):\n",
        "    init = input\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init._keras_shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling3D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "def squeeze_excite_gmp_block(input, ratio=16):\n",
        "    init = input\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init._keras_shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalMaxPooling3D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def channel_spatial_squeeze_excite(input, ratio=16):\n",
        "    ''' Create a spatial squeeze-excite block\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "    Returns: a keras tensor\n",
        "    References\n",
        "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
        "    -   [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)\n",
        "    '''\n",
        "\n",
        "    cse = squeeze_excite_gap_block(input, ratio)\n",
        "    sse = squeeze_excite_gmp_block(input, ratio)\n",
        "    \n",
        "    x = maximum([cse, sse])   #Lots of funsion can be done line average, max etc.\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBJNnvEjZCPr",
        "colab_type": "text"
      },
      "source": [
        "# SE-Resnet8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pc2rNRiZFwb",
        "colab_type": "code",
        "outputId": "160690b8-8ebd-4a8f-f4e9-cbc2d20ccd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "def SE_ResNet8(input_shape,codebooks, num_outputs):\n",
        "\t_handle_dim_ordering()\n",
        "\tif len(input_shape) != 4:\n",
        "\t\traise Exception(\"Input shape should be a tuple (nb_channels, kernel_dim1, kernel_dim2, kernel_dim3)\")\n",
        "\t\n",
        "\tif K.common.image_dim_ordering() == 'tf':\n",
        "\t\tinput_shape = (input_shape[1], input_shape[2],input_shape[3], input_shape[0])\n",
        "\tinput = Input(shape = input_shape)#;print(input.shape)\n",
        "\t\n",
        "\tconv1 = _conv_bn_relu(nb_filter=32, kernel_dim1=1, kernel_dim2=1, kernel_dim3=7, subsample=(1, 1, 2))(input)#;print(conv1.shape)\n",
        "\t\n",
        "\tconv2 = basic_block_spc(32, is_first_block_of_first_layer = True)(conv1)#;print(conv2.shape)\n",
        "\tbn3 = _bn_relu(conv2)#;print(bn3.shape)\n",
        "\t#bn3 = _bn_relu(bn3_1)\n",
        "\tbn4 = _conv_bn_relu(nb_filter=128, kernel_dim1=1, kernel_dim2=1, kernel_dim3=bn3._keras_shape[CONV_DIM3], subsample=(1, 1, 2) , border_mode='valid')(bn3)\n",
        "\tresh = Reshape((bn4._keras_shape[CONV_DIM1],bn4._keras_shape[CONV_DIM2],bn4._keras_shape[CHANNEL_AXIS],1))(bn4)\n",
        "\tconv4 = _conv_bn_relu(nb_filter=32, kernel_dim1=3, kernel_dim2=3, kernel_dim3=128,\n",
        "                              subsample=(1, 1, 1))(resh)\n",
        "\tconv5 = basic_block(32, is_first_block_of_first_layer = True)(conv4)#;print(conv5.shape)\n",
        "\tbn5 = _bn_relu(conv5)\n",
        "\tbn6 = _bn_relu(bn5)\n",
        "\n",
        "\tbn6 = Reshape((bn6.shape[1],bn6.shape[2],bn6.shape[4]))(bn6)\n",
        "\t#print(bn6.shape)\n",
        "\t#pool2 = AveragePooling3D(pool_size=(bn6._keras_shape[CONV_DIM1],\n",
        "  #                                    bn6._keras_shape[CONV_DIM2],\n",
        "  #                                    bn6._keras_shape[CONV_DIM3],),strides=(1, 1, 1))(bn6)\n",
        "\t#flatten1 = Flatten()(pool2)\n",
        "\t#bn6 = K.squeeze(bn6,axis = 3)\n",
        "\tflatten1 = BoF_Pooling(codebooks, spatial_level=0)(bn6)\n",
        "\tdrop1 = Dropout(rate=0.5)(flatten1)\n",
        "\tdense = Dense(units=num_outputs, activation=\"softmax\", kernel_initializer=\"he_normal\")(drop1);print(dense.dtype,input.dtype)\n",
        "\n",
        "\tmodel = Model( inputs = input , outputs = dense)\n",
        "\t#model.summary()\n",
        "\treturn model\n",
        "model = SE_ResNet8((1,15,15,30),64,16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape: (None, 15, 15, 12, 32)\n",
            "input shape: (None, 13, 13, 1, 32)\n",
            "<dtype: 'float32'> <dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFUGxgyfHJNB",
        "colab_type": "code",
        "outputId": "88332b23-5415-4ac1-dc1e-717b5312d676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 15, 15, 30, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 15, 15, 12, 3 256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 15, 15, 12, 3 128         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 15, 15, 12, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_1 (Glo (None, 32)           0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling3d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 15, 15, 12, 3 9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1, 1, 2)      64          reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 15, 15, 12, 3 128         conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1, 1, 32)     64          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 15, 15, 12, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 15, 15, 12, 3 0           activation_1[0][0]               \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 15, 15, 12, 3 9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 15, 15, 12, 3 0           multiply_1[0][0]                 \n",
            "                                                                 conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 15, 15, 12, 3 128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 15, 15, 12, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 15, 15, 1, 12 49280       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 1, 12 512         conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 1, 12 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 15, 15, 128,  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 13, 13, 1, 32 36896       reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 13, 13, 1, 32 128         conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 13, 13, 1, 32 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 13, 13, 1, 32 1056        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_2 (Glo (None, 32)           0           conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling3d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 13, 13, 1, 32 9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1, 1, 2)      64          reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 13, 13, 1, 32 128         conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1, 1, 32)     64          dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 13, 13, 1, 32 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 13, 13, 1, 32 0           conv3d_8[0][0]                   \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 13, 13, 1, 32 9248        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 13, 13, 1, 32 0           multiply_2[0][0]                 \n",
            "                                                                 conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 13, 13, 1, 32 128         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 13, 13, 1, 32 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 13, 13, 1, 32 128         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 13, 13, 1, 32 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, Dimension(13) 0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bo_f__pooling_1 (BoF_Pooling)   (None, 64)           2112        reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           bo_f__pooling_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           1040        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 129,296\n",
            "Trainable params: 128,592\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVICYeeCAvVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_bof_layers(model, data, n_samples=100, n_feature_samples=5000, batch_size=32, k_means_max_iters=300,\n",
        "                          k_means_n_init=4):\n",
        "    #print(data.shape)\n",
        "    for i in range(len(model.layers)):\n",
        "        if isinstance(model.layers[i], BoF_Pooling):\n",
        "            print(\"Found BoF layer (layer %d), initializing...\" % i)\n",
        "            cur_layer = model.layers[i]\n",
        "\n",
        "            # Compile a function for getting the feature vectors\n",
        "            get_features = K.function([model.input] + [K.learning_phase()], [model.layers[i].input])\n",
        "            features = []\n",
        "            for j in range(int(n_samples / batch_size)):\n",
        "                cur_feats = get_features([data[j * batch_size:(j + 1) * batch_size], 0])[0]\n",
        "                #print(cur_feats.shape)\n",
        "                features.append(cur_feats.reshape((-1, cur_feats.shape[3])))\n",
        "            features = np.concatenate(features)\n",
        "            np.random.shuffle(features)\n",
        "            features = features[:n_feature_samples]\n",
        "\n",
        "            # Cluster the features\n",
        "            kmeans = KMeans(n_clusters=cur_layer.N_k, n_init=k_means_n_init, max_iter=k_means_max_iters)\n",
        "            kmeans.fit(features)\n",
        "            V = kmeans.cluster_centers_.T\n",
        "            V = V.reshape((1, 1, V.shape[0], V.shape[1]))\n",
        "\n",
        "            # Set the value for the codebook\n",
        "            K.set_value(cur_layer.V, np.float32(V))\n",
        "\n",
        "            # Get the mean distance for initializing the sigmas\n",
        "            mean_dist = np.mean(pairwise_distances(features[:100]))\n",
        "\n",
        "            # Set the value for sigmas\n",
        "            sigmas = np.ones((1, 1, 1, cur_layer.N_k)) * (mean_dist ** 2)\n",
        "            K.set_value(cur_layer.sigmas, np.float32(sigmas))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfkWMf-mUUSw",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77wZ_eo5UWLM",
        "colab_type": "code",
        "outputId": "d062edd3-7bfe-4cfa-c612-a92ff1ce15fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# compiling the model\n",
        "adam = Adam(lr=0.001, decay=1e-06)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "initialize_bof_layers(model, Xtrain,n_samples=Xtrain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found BoF layer (layer 39), initializing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHqNrQEwUWbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint\n",
        "filepath = \"best-model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD82HIsAUl93",
        "colab_type": "code",
        "outputId": "ee637752-e633-4edd-9cf4-51e0045c5194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "history = model.fit(x=Xtrain, y=ytrain, batch_size= 32, epochs=200 ,callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1537/1537 [==============================] - 4s 3ms/step - loss: 3.6697 - acc: 0.0891\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.08913, saving model to best-model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-812f7de557df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: 13"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBMBeF4NUrW6",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaF60uD0UtiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtTU0znUEuG-",
        "colab_type": "text"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UA0c-CSEuG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best weights\n",
        "#model.load_weights(\"best-model.hdf5\")\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyIg3whQpXsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT3Emib1EuHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_test = model.predict(Xtest)\n",
        "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
        "\n",
        "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
        "print(classification)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI2I21s05K_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best weights\n",
        "model.load_weights(\"best-model.hdf5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAo6oewM5KEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_test = model.predict(Xtest)\n",
        "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
        "\n",
        "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
        "print(classification)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVzFcKxkEuHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AA_andEachClassAccuracy(confusion_matrix):\n",
        "    counter = confusion_matrix.shape[0]\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return each_acc, average_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UArbNVAEuHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reports (X_test,y_test,name):\n",
        "    #start = time.time()\n",
        "    Y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    #end = time.time()\n",
        "    #print(end - start)\n",
        "    if name == 'IP':\n",
        "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
        "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
        "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
        "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
        "                        'Stone-Steel-Towers']\n",
        "    elif name == 'SA':\n",
        "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
        "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
        "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
        "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
        "    elif name == 'PU':\n",
        "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
        "                        'Self-Blocking Bricks','Shadows']\n",
        "    \n",
        "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
        "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "    Test_Loss =  score[0]*100\n",
        "    Test_accuracy = score[1]*100\n",
        "    \n",
        "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzpdWcQ_EuHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)\n",
        "classification = str(classification)\n",
        "confusion = str(confusion)\n",
        "file_name = \"classification_report_\"+\"dataset=\"+dataset+\"_window_size=\"+str(windowSize)+\"_test_ratio=\"+str(test_ratio)+\".txt\"\n",
        "\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(classification))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(confusion))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}Class-wise accuracy (%)'.format(each_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS36nGcNEuHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Patch(data,height_index,width_index):\n",
        "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
        "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
        "    patch = data[height_slice, width_slice, :]\n",
        "    \n",
        "    return patch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-36p6QoEuHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the original image\n",
        "X, y = loadData(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcidLqsnEuHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = y.shape[0]\n",
        "width = y.shape[1]\n",
        "PATCH_SIZE = windowSize\n",
        "numComponents = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0uR6KF8EuHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,pca = applyPCA(X, numComponents=numComponents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1mCrxnnEuH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = padWithZeros(X, PATCH_SIZE//2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X9HLoHBEuH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im1 = np.zeros((1,25,25,30,1))\n",
        "# calculate the predicted image\n",
        "outputs = np.zeros((height,width))\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        target = int(y[i,j])\n",
        "        if target == 0 :\n",
        "            continue\n",
        "        else :\n",
        "            image_patch=Patch(X,i,j)\n",
        "            #print(image_patch.shape)\n",
        "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2],1).astype('float32')                                   \n",
        "            \n",
        "            if i==20 and j==20:\n",
        "              im1 = X_test_image\n",
        "              \n",
        "            prediction = (model.predict(X_test_image))\n",
        "            prediction = np.argmax(prediction, axis=1)\n",
        "            outputs[i][j] = prediction+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH9sv_tLEuH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vPr5sDfEuIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nso-4C9EuIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spectral.save_rgb(\"predictions_IP_25.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEV9MRhImKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}