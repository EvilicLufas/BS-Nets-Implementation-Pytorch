{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DA_RecNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucalyptus/BS-Nets-Implementation-Pytorch/blob/master/DA_RecNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-WGRlA3KyxB",
        "colab_type": "code",
        "outputId": "b2aa2e6a-7323-4562-e9e8-d7c566cca3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization, ReLU, PReLU, MaxPool3D, Conv3DTranspose\n",
        "from keras.layers import Dropout, Input, GlobalAveragePooling2D, multiply, add, Activation, Permute\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Layer\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "# from plotly.offline import init_notebook_mode\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "# import spectral\n",
        "\n",
        "# init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7_l6NRBKyxH",
        "colab_type": "code",
        "outputId": "703a5cb5-ec62-4720-c05d-368110434332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!pip install -U spectral\n",
        "if not (os.path.isfile('/content/Indian_pines_corrected.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
        "if not (os.path.isfile('/content/Indian_pines_gt.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spectral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/8e/db1d750fb0153027e4e945f91f04b72a3b8b9a0cfdc2c8a33bedcb27740d/spectral-0.20.tar.gz (143kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 81kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 102kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 112kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 122kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 133kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.17.3)\n",
            "Building wheels for collected packages: spectral\n",
            "  Building wheel for spectral (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectral: filename=spectral-0.20-cp36-none-any.whl size=183918 sha256=f807d5f8c115f87d90e15fb6f388e34c8357ff45280d89fdafc38a2284784f4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/cf/f3/3cab28f6aed46f15c8db09c6ad678483610426261025e61ff8\n",
            "Successfully built spectral\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.20\n",
            "--2019-11-01 20:07:50--  http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5953527 (5.7M) [text/plain]\n",
            "Saving to: ‘Indian_pines_corrected.mat’\n",
            "\n",
            "Indian_pines_correc 100%[===================>]   5.68M  1.53MB/s    in 3.7s    \n",
            "\n",
            "2019-11-01 20:07:54 (1.53 MB/s) - ‘Indian_pines_corrected.mat’ saved [5953527/5953527]\n",
            "\n",
            "--2019-11-01 20:07:59--  http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1125 (1.1K) [text/plain]\n",
            "Saving to: ‘Indian_pines_gt.mat’\n",
            "\n",
            "Indian_pines_gt.mat 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-01 20:07:59 (162 MB/s) - ‘Indian_pines_gt.mat’ saved [1125/1125]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayKszFCcKyxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "    data = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "    labels = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyw923t1KyxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-pUBs9hKyxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qgTzXVKKyxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = loadData()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbCGwgrKyxT",
        "colab_type": "code",
        "outputId": "af06676d-819b-45cd-b277-36bb9f7d1760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = createImageCubes(X, y)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10249, 5, 5, 200), (10249,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmInivJsKyxW",
        "colab_type": "text"
      },
      "source": [
        "# Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl5WqJl6KyxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = X.reshape(-1, 200, 5, 5)\n",
        "# X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnbZ0zj5hdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def BAM():\n",
        "#     model = Sequential()\n",
        "#     model.add(Conv2D(filters=64,\n",
        "#                      input_shape=(200, 5, 5),\n",
        "#                      kernel_size=(3,3),\n",
        "#                      strides=1,\n",
        "#                      padding='valid', name=\"Conv1\"))\n",
        "#     model.add(ReLU(name=\"ReLU1\"))\n",
        "#     model.add(GlobalAveragePooling2D(data_format=\"channels_first\"))\n",
        "    \n",
        "#     model.add(Dense(128))\n",
        "#     model.add(ReLU(name=\"ReLU2\"))\n",
        "#     model.add(Dense(200, activation=\"sigmoid\"))\n",
        "  \n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApjsnxprVews",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PAM(Layer):\n",
        "    def __init__(self,\n",
        "                 gamma_initializer=tf.zeros_initializer(),\n",
        "                 gamma_regularizer=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(PAM, self).__init__(**kwargs)\n",
        "        self.gamma_initializer = gamma_initializer\n",
        "        self.gamma_regularizer = gamma_regularizer\n",
        "        self.gamma_constraint = gamma_constraint\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(shape=(1, ),\n",
        "                                     initializer=self.gamma_initializer,\n",
        "                                     name='gamma',\n",
        "                                     regularizer=self.gamma_regularizer,\n",
        "                                     constraint=self.gamma_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def call(self, input):\n",
        "        input_shape = input.get_shape().as_list()\n",
        "        _, h, w, filters = input_shape\n",
        "\n",
        "        b = Conv2D(filters // 8, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
        "        c = Conv2D(filters // 8, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
        "        d = Conv2D(filters, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
        "\n",
        "        vec_b = K.reshape(b, (-1, h * w, filters // 8))\n",
        "        vec_cT = tf.transpose(K.reshape(c, (-1, h * w, filters // 8)), (0, 2, 1))\n",
        "        bcT = K.batch_dot(vec_b, vec_cT)\n",
        "        softmax_bcT = Activation('softmax')(bcT)\n",
        "        vec_d = K.reshape(d, (-1, h * w, filters))\n",
        "        bcTd = K.batch_dot(softmax_bcT, vec_d)\n",
        "        bcTd = K.reshape(bcTd, (-1, h, w, filters))\n",
        "\n",
        "        out = self.gamma*bcTd + input\n",
        "        return out\n",
        "\n",
        "\n",
        "class CAM(Layer):\n",
        "    def __init__(self,\n",
        "                 gamma_initializer=tf.zeros_initializer(),\n",
        "                 gamma_regularizer=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(CAM, self).__init__(**kwargs)\n",
        "        self.gamma_initializer = gamma_initializer\n",
        "        self.gamma_regularizer = gamma_regularizer\n",
        "        self.gamma_constraint = gamma_constraint\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(shape=(1, ),\n",
        "                                     initializer=self.gamma_initializer,\n",
        "                                     name='gamma',\n",
        "                                     regularizer=self.gamma_regularizer,\n",
        "                                     constraint=self.gamma_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def call(self, input):\n",
        "        input_shape = input.get_shape().as_list()\n",
        "        _, h, w, filters = input_shape\n",
        "\n",
        "        vec_a = K.reshape(input, (-1, h * w, filters))\n",
        "        vec_aT = tf.transpose(vec_a, (0, 2, 1))\n",
        "        aTa = K.batch_dot(vec_aT, vec_a)\n",
        "        softmax_aTa = Activation('softmax')(aTa)\n",
        "        aaTa = K.batch_dot(vec_a, softmax_aTa)\n",
        "        aaTa = K.reshape(aaTa, (-1, h, w, filters))\n",
        "\n",
        "        out = self.gamma*aaTa + input\n",
        "        return out\n",
        "      \n",
        "def DA():\n",
        "    input_layer = Input((5, 5, 200))\n",
        "    pam = PAM()(input_layer)\n",
        "    cam = CAM()(input_layer)\n",
        "    \n",
        "    feature_sum = add([pam, cam])\n",
        "    \n",
        "    return Model(inputs=input_layer, outputs=feature_sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvQBnOxVKyxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DCAE(weight_decay=0.0005):\n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(filters=24,\n",
        "                     input_shape=(200, 5, 5, 1),\n",
        "                     kernel_size=(24, 3, 3),\n",
        "                     strides=(1, 1, 1),\n",
        "                     kernel_regularizer=regularizers.l2(l=weight_decay),\n",
        "                     padding='valid', name=\"Conv1\"))\n",
        "    model.add(BatchNormalization(name=\"BN1\"))\n",
        "    model.add(PReLU(name=\"PReLU1\"))\n",
        "\n",
        "    model.add(Conv3D(filters=48,\n",
        "                     kernel_size=(24, 3, 3),\n",
        "                     strides=(1, 1, 1),\n",
        "                     kernel_regularizer=regularizers.l2(l=weight_decay),\n",
        "                     padding='valid', name=\"Conv2\"))\n",
        "    model.add(BatchNormalization(name=\"BN2\"))\n",
        "    model.add(PReLU(name=\"PReLU2\"))\n",
        "\n",
        "    model.add(MaxPool3D(pool_size=(18, 1, 1),\n",
        "                        strides=(18, 1, 1), name=\"Pool1\"))\n",
        "\n",
        "    model.add(Conv3DTranspose(filters=24,\n",
        "                              kernel_size=(9, 3, 3),\n",
        "                              kernel_regularizer=regularizers.l2(\n",
        "                                  l=weight_decay),\n",
        "                              strides=(22, 1, 1), name=\"Deconv1\", padding='valid'))\n",
        "    model.add(BatchNormalization(name=\"BN3\"))\n",
        "    model.add(PReLU(name=\"PReLU3\"))\n",
        "    model.add(Conv3DTranspose(filters=1,\n",
        "                              kernel_size=(25, 3, 3),\n",
        "                              kernel_regularizer=regularizers.l2(\n",
        "                                  l=weight_decay),\n",
        "                              strides=(1, 1, 1), name=\"Deconv2\", padding='valid'))\n",
        "    model.add(BatchNormalization(name=\"BN4\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtnuhhpDAC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ensemble():\n",
        "    input_layer = Input((5, 5, 200))\n",
        "#     band_activations = BAM()(input_layer)\n",
        "#     band_activations = Reshape((200, 1, 1))(band_activations)\n",
        "    \n",
        "#     bam_output = multiply([band_activations, input_layer])\n",
        "    \n",
        "#     bam_output = Reshape((200, 5, 5, 1))(bam_output)\n",
        "    da_output = DA()(input_layer)\n",
        "    da_output = Permute((3,1,2), input_shape=(5,5,200))(da_output)\n",
        "    da_output = Reshape((200, 5, 5, 1))(da_output)\n",
        "    output = DCAE()(da_output)\n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer, outputs=output)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdiDxfoAKyxb",
        "colab_type": "code",
        "outputId": "b9a720c7-11bb-41f9-fed9-19a4c1deb5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# model = DCAE(weight_decay=0.0005)\n",
        "model = Ensemble()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 5, 5, 200)         0         \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 5, 5, 200)         2         \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 200, 5, 5)         0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 200, 5, 5, 1)      0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 200, 5, 5, 1)      436853    \n",
            "=================================================================\n",
            "Total params: 436,855\n",
            "Trainable params: 436,661\n",
            "Non-trainable params: 194\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ9vjeqYKyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psnr(x_true, x_pred):\n",
        "    n_samples = x_true.shape[0]\n",
        "    n_bands = x_true.shape[1]\n",
        "    PSNR = np.zeros(n_bands)\n",
        "    MSE = np.zeros(n_bands)\n",
        "    mask = np.ones(n_bands)\n",
        "    for k in range(n_bands):\n",
        "        x_true_k = x_true[:, k].reshape([-1])\n",
        "        x_pred_k = x_pred[:, k].reshape([-1])\n",
        "        MSE[k] = 1.0 / n_samples * mean_squared_error(x_true_k, x_pred_k, )\n",
        "        MAX_k = np.max(x_true_k)\n",
        "        if MAX_k != 0:\n",
        "            PSNR[k] = 10 * math.log10(math.pow(MAX_k, 2) / MSE[k])\n",
        "        else:\n",
        "            mask[k] = 0\n",
        "\n",
        "    psnr = PSNR.sum()/mask.sum()\n",
        "    mse = MSE.mean()\n",
        "    print('psnr', psnr)\n",
        "    print('mse', mse)\n",
        "    \n",
        "    return psnr, mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxjZ9mdUblcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from scipy.special import kl_div\n",
        "def Dskl(Bi,Bj):\n",
        "  \n",
        "  \n",
        "  pk = np.histogramdd(np.ravel(Bi), bins = 256)[0]/Bi.size \n",
        "  #pk = list(filter(lambda p: p > 0, pk))\n",
        "  pk = np.array(pk)\n",
        "\n",
        "  qk = np.histogramdd(np.ravel(Bj), bins = 256)[0]/Bj.size\n",
        "  #qk = list(filter(lambda p: p > 0, qk)\n",
        "  qk = np.array(qk)\n",
        "  \n",
        "  \n",
        "  S = kl_div(pk,qk) + kl_div(qk,pk)\n",
        "  \n",
        "  #S = np.sum(pk * np.log2(pk / qk), axis=0) + np.sum(qk * np.log2(qk / pk), axis=0)\n",
        "  \n",
        "  return S"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lt3ejW8OkA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENTROPY = np.zeros(200)\n",
        "import skimage    \n",
        "def top15bands(x_predict):\n",
        "  for i in range(0,len(ENTROPY)):\n",
        "    ENTROPY[i]+=skimage.measure.shannon_entropy(x_predict[:,i,:,:])\n",
        "  \n",
        "  print('Top 15 bands with Entropy ->',ENTROPY.argsort()[-15:][::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4bEPCGGYyP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSD(x_predict):\n",
        "  top15 = ENTROPY.argsort()[-15:][::-1]\n",
        "  perbatch = list(0 for i in range(0,160))\n",
        "  for batch_idx in range(0,len(perbatch)):\n",
        "    for i in range(0,len(top15)):\n",
        "      for j in range(0,i):\n",
        "        perbatch[batch_idx]+=Dskl(x_predict[:,top15[i],:,:],x_predict[:,top15[j],:,:])\n",
        "  perbatch = np.array(perbatch)\n",
        "  perbatch[perbatch>=1E03]=0\n",
        "  print('Mean of MSD with Top 15 bands is \\n',np.mean(perbatch)*100)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x0UcifSKyxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "\n",
        "class MyLogger(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_predict = model.predict(X)\n",
        "        x_true = np.asarray(X)\n",
        "        x_pred_centre = x_predict[:, :, 2, 2]\n",
        "        x_true_centre = x_true[:, :, 2, 2]\n",
        "        psnr(x_true_centre, x_pred_centre)\n",
        "        top15bands(x_predict)\n",
        "    def on_train_end(self,logs=None):\n",
        "      x_predict = model.predict(X)\n",
        "      MSD(x_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJYuFFA6Kyxl",
        "colab_type": "code",
        "outputId": "c3406582-7eb1-4f7a-9a51-554a9d67a98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model.compile(loss=keras.losses.mse, optimizer=keras.optimizers.Adam(lr=0.1))\n",
        "\n",
        "n_epoch = 100\n",
        "\n",
        "\n",
        "model.fit(X, X.reshape(-1, 200, 5, 5, 1), epochs=n_epoch, shuffle=True, verbose=1, batch_size=32, callbacks=[MyLogger()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "10249/10249 [==============================] - 16s 2ms/step - loss: 5070529.8298\n",
            "psnr 45.73431634597225\n",
            "mse 1041.1729192428718\n",
            "Top 15 bands with Entropy -> [ 12   4  20   5  52  13 140  53  36  76  29  28 116 157  21]\n",
            "Mean of MSD with Top 15 bands is \n",
            " 54.6476714974499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed75e41c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}